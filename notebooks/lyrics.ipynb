{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "T = torch.Tensor\n",
    "M = nn.Module\n",
    "\n",
    "\n",
    "from tokenizers import (\n",
    "    decoders,\n",
    "    models,\n",
    "    normalizers,\n",
    "    pre_tokenizers,\n",
    "    trainers,\n",
    "    Tokenizer,\n",
    ")\n",
    "import re\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(530, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/taylor_lyrics_2.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mine</td>\n",
       "      <td>[Verse 1]\\nYou were in college, working part-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Back to December</td>\n",
       "      <td>[Verse 1]\\nI'm so glad you made time to see me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thug Story</td>\n",
       "      <td>[Intro: T-Pain]\\nHey Hey, T-Swizzle (T-Swizzle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Speak Now</td>\n",
       "      <td>[Verse 1]\\nI am not the kind of girl\\nWho shou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Haunted</td>\n",
       "      <td>[Verse 1]\\nYou and I walk a fragile line\\nI ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              title                                             lyrics\n",
       "0              Mine  [Verse 1]\\nYou were in college, working part-t...\n",
       "1  Back to December  [Verse 1]\\nI'm so glad you made time to see me...\n",
       "2        Thug Story  [Intro: T-Pain]\\nHey Hey, T-Swizzle (T-Swizzle...\n",
       "3         Speak Now  [Verse 1]\\nI am not the kind of girl\\nWho shou...\n",
       "4           Haunted  [Verse 1]\\nYou and I walk a fragile line\\nI ha..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have about 530 full lyrics of songs from Taylor Swift. some of them are duplicated and some are not exactly lyrics but are transcript of interviews etc. I have attemped to remove some duplicates and non-lyrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible different version: 79\n",
      "From the vault: 14\n",
      "Removing 65 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(465, 2)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_different_version = df[\"title\"].str.contains(\"Version\")\n",
    "from_the_vault = df[\"title\"].str.contains(\"Taylors Version From the Vault\")\n",
    "\n",
    "print(f\"Possible different version: {possible_different_version.sum()}\")\n",
    "print(f\"From the vault: {from_the_vault.sum()}\")\n",
    "# remove possible different version but keep from the vault\n",
    "to_remove = possible_different_version & ~from_the_vault\n",
    "print(f\"Removing {to_remove.sum()} rows\")\n",
    "df = df[~to_remove]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the lyrics are usually very long, we can not train the model on the full lyrics. We need to create subparts of the lyrics. One way to do this is to create a sliding window of fixed size and slide it over the lyrics. A better way would be to take out the different sections of the lyrics, like chorus, verse, bridge etc. and train the model on these sections. This way the model will learn the structure of the song and will be able to generate lyrics in the same structure. The dataset is organized in a way that the sections names are given in the lyrics. We can use this information to create the subparts. Here is the lyrics of `willow` from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Verse 1]\n",
      "I'm like the water when your ship rolled in that night\n",
      "Rough on the surface, but you cut through like a knife\n",
      "And if it was an open-shut case\n",
      "I never would've known from that look on your face\n",
      "Lost in your current like a priceless wine\n",
      "\n",
      "[Chorus]\n",
      "The more that you say, the less I know\n",
      "Wherever you stray, I follow\n",
      "I'm begging for you to take my hand\n",
      "Wreck my plans, that's my man\n",
      "\n",
      "[Verse 2]\n",
      "Life was a willow and it bent right to your wind\n",
      "Head on the pillow, I could feel you sneakin' in\n",
      "As if you were a mythical thing\n",
      "Like you were a trophy or a champion ring\n",
      "And there was one prize I'd cheat to win\n",
      "\n",
      "[Chorus]\n",
      "The more that you say, the less I know\n",
      "Wherever you stray, I follow\n",
      "I'm begging for you to take my hand\n",
      "Wreck my plans, that's my man\n",
      "You know that my train could take you home\n",
      "Anywhere else is hollow\n",
      "I'm begging for you to take my hand\n",
      "Wreck my plans, that's my man\n",
      "[Bridge]\n",
      "Life was a willow and it bent right to your wind\n",
      "They count me out time and time again\n",
      "Life was a willow and it bent right to your wind\n",
      "But I come back stronger than a '90s trend\n",
      "\n",
      "[Verse 3]\n",
      "Wait for the signal, and I'll meet you after dark\n",
      "Show me the places where the others gave you scars\n",
      "Now this is an open-shut case\n",
      "I guess I should've known from the look on your face\n",
      "Every bait-and-switch was a work of art\n",
      "\n",
      "[Chorus]\n",
      "The more that you say, the less I know\n",
      "Wherever you stray, I follow\n",
      "I'm begging for you to take my hand\n",
      "Wreck my plans, that's my man\n",
      "You know that my train could take you home\n",
      "Anywhere else is hollow\n",
      "I'm begging for you to take my hand\n",
      "Wreck my plans, that's my man\n",
      "The more that you say, the less I know\n",
      "Wherever you stray, I follow\n",
      "I'm begging for you to take my hand\n",
      "Wreck my plans, that's my man\n",
      "You know that my train could take you home\n",
      "Anywhere else is hollow\n",
      "I'm begging for you to take my hand\n",
      "Wreck my plans, that's my man\n",
      "[Outro]\n",
      "Hey, that's my man\n",
      "That's my man\n",
      "Yeah, that's my man\n",
      "Every bait-and-switch was a work of art\n",
      "That's my man\n",
      "Hey, that's my man\n",
      "I'm begging for you to take my hand\n",
      "Wreck my plans, that's my man\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[429, \"lyrics\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code cells extracts the section name and the lyrics of the section from the lyrics of the song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_lyric(lyric):\n",
    "    song_section_name_re = re.compile(r\"\\[([a-zA-Z\\s-]*):?\\d*:?.*\\]\")\n",
    "    song_section_spans = [i.span() for i in song_section_name_re.finditer(lyric)]\n",
    "    if len(song_section_spans) == 0:\n",
    "        print(\"No sections found. Using default section name 'verse'\")\n",
    "        # use \\n\\n to split\n",
    "        sections = lyric.split(\"\\n\\n\")\n",
    "        song_sections = [\"verse\"] * len(sections)\n",
    "        song_with_sections = {\n",
    "            \"sections\": [\n",
    "                {\"section\": song_section, \"lyrics\": section.strip()}\n",
    "                for song_section, section in zip(song_sections, sections)\n",
    "            ]\n",
    "        }\n",
    "        return song_with_sections[\"sections\"]\n",
    "\n",
    "    song_sections = song_section_name_re.findall(lyric)\n",
    "    song_lyric_spans = [\n",
    "        (song_section_spans[i][1], song_section_spans[i + 1][0])\n",
    "        for i in range(len(song_section_spans) - 1)\n",
    "    ]\n",
    "    song_lyric_spans.append((song_section_spans[-1][1], len(lyric))) # last section\n",
    "\n",
    "    song_with_sections = {\n",
    "        \"sections\": [\n",
    "            {\n",
    "                \"section\":song_section.strip(),\n",
    "                \"lyrics\": lyric[song_span[0] : song_span[1]].strip(),\n",
    "            }\n",
    "            for song_section, song_span in zip(song_sections, song_lyric_spans)\n",
    "        ]\n",
    "    }\n",
    "    return song_with_sections[\"sections\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n",
      "No sections found. Using default section name 'verse'\n"
     ]
    }
   ],
   "source": [
    "songs_section_wise = {}\n",
    "for idx, row in df.iterrows():\n",
    "    try:\n",
    "        songs_section_wise[row[\"title\"]] = preprocess_lyric(row[\"lyrics\"])\n",
    "    except Exception as e:\n",
    "        print(idx)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "songs_file_path = \"../data/songs_section_wise.json\"\n",
    "with open(songs_file_path, \"w\") as f:\n",
    "    json.dump(songs_section_wise, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will load the dataset and tokenize the lyrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3544"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_all_lyrics(songs_file_path):\n",
    "    with open(songs_file_path, \"r\") as f:\n",
    "        songs = json.load(f)\n",
    "    lyrics = []\n",
    "    for _, sections in songs.items():\n",
    "\n",
    "        for section in sections:\n",
    "            lyrics.append(section[\"lyrics\"])\n",
    "\n",
    "    return lyrics\n",
    "\n",
    "\n",
    "lyrics = fetch_all_lyrics(songs_file_path)\n",
    "len(lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(models.WordPiece(unk_token=\"[UNK]\"))\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.BertPreTokenizer()\n",
    "tokenizer.decoder = decoders.WordPiece()\n",
    "tokenizer.normalizer = normalizers.Sequence(\n",
    "    [normalizers.NFD(), normalizers.Lowercase(), normalizers.StripAccents()]\n",
    ")\n",
    "\n",
    "trainer = trainers.WordPieceTrainer(\n",
    "    vocab_size=10000, special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"]\n",
    ")\n",
    "\n",
    "tokenizer.train_from_iterator(lyrics, trainer=trainer)\n",
    "\n",
    "# now save the tokenizer\n",
    "tokenizer.save(\"../data/tokenizer_eng_lyrics.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = [len(tokenizer.encode(lyric).ids) for lyric in lyrics]\n",
    "max_len = max(lengths)\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3544.000000\n",
       "mean       50.093115\n",
       "std        31.762309\n",
       "min         0.000000\n",
       "25%        28.000000\n",
       "50%        46.000000\n",
       "75%        64.000000\n",
       "max       283.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = pd.Series(lengths)\n",
    "lengths.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
